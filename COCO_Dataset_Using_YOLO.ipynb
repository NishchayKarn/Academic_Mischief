{
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.14",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [
        {
          "sourceId": 1462296,
          "sourceType": "datasetVersion",
          "datasetId": 857191
        }
      ],
      "dockerImageVersionId": 30762,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "name": "COCO Dataset Using YOLO",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NishchayKarn/Academic_Mischief/blob/main/COCO_Dataset_Using_YOLO.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "source": [
        "\n",
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES\n",
        "# TO THE CORRECT LOCATION (/kaggle/input) IN YOUR NOTEBOOK,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "\n",
        "import os\n",
        "import sys\n",
        "from tempfile import NamedTemporaryFile\n",
        "from urllib.request import urlopen\n",
        "from urllib.parse import unquote, urlparse\n",
        "from urllib.error import HTTPError\n",
        "from zipfile import ZipFile\n",
        "import tarfile\n",
        "import shutil\n",
        "\n",
        "CHUNK_SIZE = 40960\n",
        "DATA_SOURCE_MAPPING = 'coco-2017-dataset:https%3A%2F%2Fstorage.googleapis.com%2Fkaggle-data-sets%2F857191%2F1462296%2Fbundle%2Farchive.zip%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com%252F20241010%252Fauto%252Fstorage%252Fgoog4_request%26X-Goog-Date%3D20241010T191041Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3D890888898be543c7645cb3856c7696f714f3b696150c49c896059a04c20a2180d694b93d73dd085d1c592ccbdace98c3c996c44adcc8354d5c19745ea4486726c19edc437c4a9408622d931207362f11c50a262c04b87c8783cf7b591287d9dc9a2c1832fa794a589cf9385f7ab285fd875741f92494497680ff6c47a6705291ad0a11edadad2b80aedf057dfd58593f4d85fe818bca05700c91df2238a419b1cced014f349ad5d8d42702b5322be6d55ba52a4ed668e7268ff40d1a3ef6b3f4c52d6b5571ca3fee5df35914b3caf24e256cbe83babd13c3ef645eb95fb1b0c42cef2bfd77b9a1ee2ab833538474f7b1c190b67419b1a3c1232c21419ff61eb2'\n",
        "\n",
        "KAGGLE_INPUT_PATH='/kaggle/input'\n",
        "KAGGLE_WORKING_PATH='/kaggle/working'\n",
        "KAGGLE_SYMLINK='kaggle'\n",
        "\n",
        "!umount /kaggle/input/ 2> /dev/null\n",
        "shutil.rmtree('/kaggle/input', ignore_errors=True)\n",
        "os.makedirs(KAGGLE_INPUT_PATH, 0o777, exist_ok=True)\n",
        "os.makedirs(KAGGLE_WORKING_PATH, 0o777, exist_ok=True)\n",
        "\n",
        "try:\n",
        "  os.symlink(KAGGLE_INPUT_PATH, os.path.join(\"..\", 'input'), target_is_directory=True)\n",
        "except FileExistsError:\n",
        "  pass\n",
        "try:\n",
        "  os.symlink(KAGGLE_WORKING_PATH, os.path.join(\"..\", 'working'), target_is_directory=True)\n",
        "except FileExistsError:\n",
        "  pass\n",
        "\n",
        "for data_source_mapping in DATA_SOURCE_MAPPING.split(','):\n",
        "    directory, download_url_encoded = data_source_mapping.split(':')\n",
        "    download_url = unquote(download_url_encoded)\n",
        "    filename = urlparse(download_url).path\n",
        "    destination_path = os.path.join(KAGGLE_INPUT_PATH, directory)\n",
        "    try:\n",
        "        with urlopen(download_url) as fileres, NamedTemporaryFile() as tfile:\n",
        "            total_length = fileres.headers['content-length']\n",
        "            print(f'Downloading {directory}, {total_length} bytes compressed')\n",
        "            dl = 0\n",
        "            data = fileres.read(CHUNK_SIZE)\n",
        "            while len(data) > 0:\n",
        "                dl += len(data)\n",
        "                tfile.write(data)\n",
        "                done = int(50 * dl / int(total_length))\n",
        "                sys.stdout.write(f\"\\r[{'=' * done}{' ' * (50-done)}] {dl} bytes downloaded\")\n",
        "                sys.stdout.flush()\n",
        "                data = fileres.read(CHUNK_SIZE)\n",
        "            if filename.endswith('.zip'):\n",
        "              with ZipFile(tfile) as zfile:\n",
        "                zfile.extractall(destination_path)\n",
        "            else:\n",
        "              with tarfile.open(tfile.name) as tarfile:\n",
        "                tarfile.extractall(destination_path)\n",
        "            print(f'\\nDownloaded and uncompressed: {directory}')\n",
        "    except HTTPError as e:\n",
        "        print(f'Failed to load (likely expired) {download_url} to path {destination_path}')\n",
        "        continue\n",
        "    except OSError as e:\n",
        "        print(f'Failed to load {download_url} to path {destination_path}')\n",
        "        continue\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "id": "FMbO8CI31zLv"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# COCO Dataset to YOLO Format Conversion and Training with Ultralytics YOLOv8"
      ],
      "metadata": {
        "_uuid": "f29d5c18-9cb3-4246-8783-e36e611437c4",
        "_cell_guid": "4000c406-55c0-47c9-973a-e4a4465a9a86",
        "trusted": true,
        "id": "6LoNak4m1zLx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This notebook converts the COCO dataset into YOLO format and trains a YOLOv8 model using Ultralytics. It supports different annotation types: bounding boxes, segmentation masks, and keypoints.\n",
        "\n",
        "**Key Features:**\n",
        "\n",
        "* **Annotation Type Selection:** Choose between 'bbox', 'segmentation', and 'keypoints'.\n",
        "* **Data Reduction:** Optionally reduce the training and validation datasets for faster experimentation.\n",
        "* **Parallel Processing:** Utilizes multiple CPU cores for efficient data conversion.\n",
        "* **Automatic Configuration:** Generates a `config.yaml` file for YOLOv8 training.\n",
        "* **Training Visualization:** Displays training results with confusion matrix and metrics plots.\n",
        "* **Prediction Example:** Demonstrates prediction on sample images."
      ],
      "metadata": {
        "_uuid": "2ef05909-6795-4057-8048-59de6ef237ed",
        "_cell_guid": "9126ec1b-b5b2-4e7b-a8e3-df4dcb081bb7",
        "trusted": true,
        "id": "RNMrT0DG1zLy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "import shutil\n",
        "import random\n",
        "from tqdm import tqdm\n",
        "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
        "from pathlib import Path\n",
        "import numpy as np"
      ],
      "metadata": {
        "_uuid": "f89dde71-f71d-4000-a60f-8c10fd961733",
        "_cell_guid": "acb5698e-5d9b-4587-b884-25807d61298a",
        "jupyter": {
          "outputs_hidden": false
        },
        "execution": {
          "iopub.status.busy": "2024-08-28T15:32:05.534625Z",
          "iopub.execute_input": "2024-08-28T15:32:05.534982Z",
          "iopub.status.idle": "2024-08-28T15:32:05.551083Z",
          "shell.execute_reply.started": "2024-08-28T15:32:05.534947Z",
          "shell.execute_reply": "2024-08-28T15:32:05.550075Z"
        },
        "trusted": true,
        "id": "K4Yq_q0L1zLz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Configuration"
      ],
      "metadata": {
        "_uuid": "a689ef71-6e53-443a-9ab3-9fbcfdeade04",
        "_cell_guid": "be933fae-c1c1-4f04-b2c1-cffce6ce0b1f",
        "trusted": true,
        "id": "QnkU3Uje1zLz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the home directory\n",
        "HOME = Path.cwd()\n",
        "\n",
        "# Set paths\n",
        "COCO_PATH = Path('/kaggle/input/coco-2017-dataset/coco2017')\n",
        "OUTPUT_PATH = HOME / 'data'\n",
        "\n",
        "# Choose your desired annotation type: 'bbox', 'keypoints', or 'segmentation'\n",
        "chosen_annotation_type = 'segmentation'\n",
        "\n",
        "# Data reduction factors (set to 1.0 to use the full dataset)\n",
        "train_reduce_factor = 0.1\n",
        "val_reduce_factor = 0.2"
      ],
      "metadata": {
        "_uuid": "dff94f3e-ad86-4b75-b8d0-a703972003fe",
        "_cell_guid": "0e159596-218e-4b6f-8653-4deb3f7ace5d",
        "jupyter": {
          "outputs_hidden": false
        },
        "execution": {
          "iopub.status.busy": "2024-08-28T15:32:05.558529Z",
          "iopub.execute_input": "2024-08-28T15:32:05.558923Z",
          "iopub.status.idle": "2024-08-28T15:32:05.564648Z",
          "shell.execute_reply.started": "2024-08-28T15:32:05.558888Z",
          "shell.execute_reply": "2024-08-28T15:32:05.563596Z"
        },
        "trusted": true,
        "id": "8wHoh-Dg1zLz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Helper Functions"
      ],
      "metadata": {
        "_uuid": "24a68da9-c607-486a-8beb-35236205ea32",
        "_cell_guid": "f578cdf2-4add-467b-a8e8-d4008341256e",
        "trusted": true,
        "id": "kHF8lsf71zLz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to convert COCO bbox to YOLO format\n",
        "def coco_to_yolo_bbox(bbox, img_width, img_height):\n",
        "    x_center = (bbox[0] + bbox[2] / 2) / img_width\n",
        "    y_center = (bbox[1] + bbox[3] / 2) / img_height\n",
        "    width = bbox[2] / img_width\n",
        "    height = bbox[3] / img_height\n",
        "    return [x_center, y_center, width, height]\n",
        "\n",
        "# Function to convert COCO segmentation to YOLO format\n",
        "def coco_to_yolo_seg(segmentation, img_width, img_height):\n",
        "    poly = np.array(segmentation).flatten().tolist()\n",
        "    return [coord / img_width if i % 2 == 0 else coord / img_height for i, coord in enumerate(poly)]\n",
        "\n",
        "# Function to convert COCO keypoints to YOLO format\n",
        "def coco_to_yolo_keypoints(keypoints, img_width, img_height):\n",
        "    yolo_keypoints = []\n",
        "    for i in range(0, len(keypoints), 3):\n",
        "        x, y, v = keypoints[i:i+3]\n",
        "        if v > 0:  # Only include visible keypoints\n",
        "            yolo_keypoints.extend([x / img_width, y / img_height, v])\n",
        "    # Pad with zeros if less than 17 keypoints\n",
        "    while len(yolo_keypoints) < 51:  # 17 keypoints * 3 values = 51\n",
        "        yolo_keypoints.extend([0, 0, 0])  # Add dummy keypoints\n",
        "    return yolo_keypoints\n",
        "\n",
        "# Function to process a single image\n",
        "def process_image(img, annotations, cat_id_to_name, split, reduce_factor, valid_class_ids, annotation_type):\n",
        "    if random.random() > reduce_factor:\n",
        "        return\n",
        "\n",
        "    img_id = img['id']\n",
        "    img_name = img['file_name']\n",
        "    img_width, img_height = img['width'], img['height']\n",
        "\n",
        "    # Copy image\n",
        "    src_img_path = COCO_PATH / f'{split}2017' / img_name\n",
        "    dst_img_path = OUTPUT_PATH / split / 'images' / img_name\n",
        "    shutil.copy(src_img_path, dst_img_path)\n",
        "\n",
        "    # Process annotations for this image\n",
        "    label_path = OUTPUT_PATH / split / 'labels' / (Path(img_name).stem + '.txt')\n",
        "    with open(label_path, 'w') as label_file:\n",
        "        for ann in annotations:\n",
        "            if ann['image_id'] == img_id:\n",
        "                cat_id = ann['category_id']\n",
        "                if cat_id in valid_class_ids:\n",
        "                    if annotation_type == 'bbox':\n",
        "                        bbox = ann['bbox']\n",
        "                        yolo_bbox = coco_to_yolo_bbox(bbox, img_width, img_height)\n",
        "                        label_file.write(f\"{valid_class_ids.index(cat_id)} {' '.join(map(str, yolo_bbox))}\\n\")\n",
        "                    elif annotation_type == 'segmentation':\n",
        "                        segmentation = ann['segmentation'][0] # Assuming single polygon\n",
        "                        yolo_seg = coco_to_yolo_seg(segmentation, img_width, img_height)\n",
        "                        label_file.write(f\"{valid_class_ids.index(cat_id)} {' '.join(map(str, yolo_seg))}\\n\")\n",
        "                    elif annotation_type == 'keypoints' and ann['category_id'] == 1: # Only for person\n",
        "                        bbox = ann['bbox']\n",
        "                        keypoints = ann['keypoints']\n",
        "                        yolo_bbox = coco_to_yolo_bbox(bbox, img_width, img_height)\n",
        "                        yolo_keypoints = coco_to_yolo_keypoints(keypoints, img_width, img_height)\n",
        "                        label_file.write(f\"0 {' '.join(map(str, yolo_bbox + yolo_keypoints))}\\n\")\n",
        "\n",
        "# Function to process dataset\n",
        "def process_dataset(split, reduce_factor=1.0, annotation_type='bbox'):\n",
        "    print(f\"Processing {split} dataset with annotation type: {annotation_type}...\")\n",
        "\n",
        "    # Load annotations\n",
        "    if annotation_type == 'keypoints':\n",
        "        annotation_file = f'person_keypoints_{split}2017.json'\n",
        "    else:\n",
        "        annotation_file = f'instances_{split}2017.json'\n",
        "\n",
        "    with open(COCO_PATH / 'annotations' / annotation_file) as f:\n",
        "        coco_data = json.load(f)\n",
        "\n",
        "    # Create category id to name mapping\n",
        "    global cat_id_to_name  # Declare cat_id_to_name as global\n",
        "    cat_id_to_name = {cat['id']: cat['name'] for cat in coco_data['categories']}\n",
        "\n",
        "    # Get valid class IDs (0-79)\n",
        "    valid_class_ids = sorted(list(cat_id_to_name.keys()))[:80]\n",
        "\n",
        "    # Create a dictionary of annotations by image_id for faster lookup\n",
        "    annotations_by_image = {}\n",
        "    for ann in coco_data['annotations']:\n",
        "        img_id = ann['image_id']\n",
        "        if img_id not in annotations_by_image:\n",
        "            annotations_by_image[img_id] = []\n",
        "        annotations_by_image[img_id].append(ann)\n",
        "\n",
        "    # Process images and annotations in parallel\n",
        "    with ThreadPoolExecutor(max_workers=os.cpu_count()) as executor:\n",
        "        futures = []\n",
        "        for img in coco_data['images']:\n",
        "            future = executor.submit(process_image, img, annotations_by_image.get(img['id'], []),\n",
        "                                     cat_id_to_name, split, reduce_factor, valid_class_ids, annotation_type)\n",
        "            futures.append(future)\n",
        "\n",
        "        for future in tqdm(as_completed(futures), total=len(futures)):\n",
        "            pass  # We're just using tqdm to show progress"
      ],
      "metadata": {
        "_uuid": "4c9bba63-aa40-49da-aa17-eb960692fd59",
        "_cell_guid": "0163649b-876c-4dda-9320-b8878394924f",
        "jupyter": {
          "outputs_hidden": false
        },
        "execution": {
          "iopub.status.busy": "2024-08-28T15:32:05.687879Z",
          "iopub.execute_input": "2024-08-28T15:32:05.688252Z",
          "iopub.status.idle": "2024-08-28T15:32:05.712346Z",
          "shell.execute_reply.started": "2024-08-28T15:32:05.688218Z",
          "shell.execute_reply": "2024-08-28T15:32:05.711274Z"
        },
        "trusted": true,
        "id": "G-ISz8111zL0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Preparation"
      ],
      "metadata": {
        "_uuid": "6b7e7f4a-7c38-4d5c-be05-ce74c01ab178",
        "_cell_guid": "b3046175-7ec3-423d-b901-d709cccd27c6",
        "trusted": true,
        "id": "gwaHBHPL1zL0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create output directories\n",
        "for split in ['train', 'val']:\n",
        "    for subdir in ['images', 'labels']:\n",
        "        (OUTPUT_PATH / split / subdir).mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# Process datasets\n",
        "process_dataset('train', reduce_factor=train_reduce_factor, annotation_type=chosen_annotation_type)\n",
        "process_dataset('val', reduce_factor=val_reduce_factor, annotation_type=chosen_annotation_type)"
      ],
      "metadata": {
        "_uuid": "98f6db78-82e2-483a-92b9-caef39513141",
        "_cell_guid": "3465fdc2-a2cf-4d44-88b4-1667599697db",
        "jupyter": {
          "outputs_hidden": false
        },
        "execution": {
          "iopub.status.busy": "2024-08-28T15:32:05.717047Z",
          "iopub.execute_input": "2024-08-28T15:32:05.718045Z",
          "iopub.status.idle": "2024-08-28T15:33:24.553417Z",
          "shell.execute_reply.started": "2024-08-28T15:32:05.717977Z",
          "shell.execute_reply": "2024-08-28T15:33:24.552309Z"
        },
        "trusted": true,
        "id": "xxLQxYkV1zL0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create `config.yaml`"
      ],
      "metadata": {
        "_uuid": "00a3a8dd-958a-4b67-a60c-57666377149a",
        "_cell_guid": "652baee2-ce4c-4f91-a40d-b8a5270da9be",
        "trusted": true,
        "id": "-UlHhp061zL0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create config.yaml based on the chosen annotation type\n",
        "if chosen_annotation_type == 'keypoints':\n",
        "    config = {\n",
        "        'path': str(OUTPUT_PATH),\n",
        "        'train': 'train/images',\n",
        "        'val': 'val/images',\n",
        "        'nc': 1,\n",
        "        'names': ['person'],\n",
        "        'kpt_shape': [17, 3],\n",
        "        'flip_idx': [0, 2, 1, 4, 3, 6, 5, 8, 7, 10, 9, 12, 11, 14, 13, 16, 15]\n",
        "    }\n",
        "else:\n",
        "    config = {\n",
        "        'path': str(OUTPUT_PATH),\n",
        "        'train': 'train/images',\n",
        "        'val': 'val/images',\n",
        "        'nc': 80,\n",
        "        'names': [cat_id_to_name[id] for id in sorted(list(cat_id_to_name.keys()))[:80]]\n",
        "    }\n",
        "with open(OUTPUT_PATH / \"config.yaml\", 'w') as f:\n",
        "    json.dump(config, f, indent=2)\n",
        "\n",
        "print(\"Dataset preprocessing completed.\")"
      ],
      "metadata": {
        "_uuid": "278fdba3-fb54-4070-902e-05dee69c2228",
        "_cell_guid": "45c581e9-f8f7-4c73-ad6b-d9b231ccf50d",
        "jupyter": {
          "outputs_hidden": false
        },
        "execution": {
          "iopub.status.busy": "2024-08-28T15:33:24.555763Z",
          "iopub.execute_input": "2024-08-28T15:33:24.556258Z",
          "iopub.status.idle": "2024-08-28T15:33:24.566844Z",
          "shell.execute_reply.started": "2024-08-28T15:33:24.556204Z",
          "shell.execute_reply": "2024-08-28T15:33:24.565679Z"
        },
        "trusted": true,
        "id": "rozB9Di51zL1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Install Ultralytics YOLOv8"
      ],
      "metadata": {
        "_uuid": "e6a2e6bf-2a95-4c56-a666-a282170622eb",
        "_cell_guid": "67f04241-c389-475b-b8cd-3d83f1df2a25",
        "trusted": true,
        "id": "8sBv4nsh1zL1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ultralytics\n",
        "!pip uninstall -y wandb  # Optional: Uninstall wandb if not needed"
      ],
      "metadata": {
        "_uuid": "06530e91-9521-4f7d-bc16-b9720a33adef",
        "_cell_guid": "b406db5d-779c-4c30-81dd-e736bdc45b89",
        "jupyter": {
          "outputs_hidden": false
        },
        "execution": {
          "iopub.status.busy": "2024-08-28T15:33:24.56804Z",
          "iopub.execute_input": "2024-08-28T15:33:24.568393Z",
          "iopub.status.idle": "2024-08-28T15:33:57.403636Z",
          "shell.execute_reply.started": "2024-08-28T15:33:24.568354Z",
          "shell.execute_reply": "2024-08-28T15:33:57.402249Z"
        },
        "trusted": true,
        "id": "I4jjYt081zL1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Training"
      ],
      "metadata": {
        "_uuid": "eebbdd5c-cc1e-498e-b74b-21771aa0cf60",
        "_cell_guid": "34add800-4e8a-4390-b2ba-75264a2eb9c7",
        "trusted": true,
        "id": "bLe7f0SU1zL1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from ultralytics import YOLO\n",
        "\n",
        "# Choose the appropriate model based on the annotation type\n",
        "if chosen_annotation_type == 'bbox':\n",
        "    model = YOLO(\"yolov8n.pt\")\n",
        "    train_folder = 'detect'\n",
        "elif chosen_annotation_type == 'segmentation':\n",
        "    model = YOLO(\"yolov8n-seg.pt\")\n",
        "    train_folder = 'segment'\n",
        "elif chosen_annotation_type == 'keypoints':\n",
        "    model = YOLO(\"yolov8n-pose.pt\")\n",
        "    train_folder = 'pose'\n",
        "\n",
        "# Train the model\n",
        "results = model.train(data=f\"{HOME}/data/config.yaml\", epochs=1, imgsz=640)"
      ],
      "metadata": {
        "_uuid": "c4c4d158-3266-4a42-b667-960eed7e18a4",
        "_cell_guid": "1754d344-e8a8-44fe-abab-b3c8b107d8a5",
        "jupyter": {
          "outputs_hidden": false
        },
        "execution": {
          "iopub.status.busy": "2024-08-28T15:33:57.407411Z",
          "iopub.execute_input": "2024-08-28T15:33:57.408447Z",
          "iopub.status.idle": "2024-08-28T15:42:28.981911Z",
          "shell.execute_reply.started": "2024-08-28T15:33:57.408405Z",
          "shell.execute_reply": "2024-08-28T15:42:28.980719Z"
        },
        "trusted": true,
        "id": "yRbTF02r1zL1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Visualize Training Results"
      ],
      "metadata": {
        "_uuid": "f0f95fb2-05a0-4fe8-8bbc-db1816f76a2e",
        "_cell_guid": "02afb404-1ba7-4da5-a074-d4dadba628d2",
        "trusted": true,
        "id": "6E-vZMw11zL1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Image\n",
        "\n",
        "# Display training results automatically\n",
        "print(f\"Displaying training results for {chosen_annotation_type}...\")\n",
        "\n",
        "!ls {HOME}/runs/{train_folder}/train\n",
        "\n",
        "Image(filename=f'{HOME}/runs/{train_folder}/train/confusion_matrix.png', width=600)"
      ],
      "metadata": {
        "_uuid": "40c14c8a-6596-4c2d-9b0f-ebab9a2697f4",
        "_cell_guid": "f45b676f-14d7-4a21-be1b-c6dff8042b28",
        "jupyter": {
          "outputs_hidden": false
        },
        "execution": {
          "iopub.status.busy": "2024-08-28T15:42:28.983384Z",
          "iopub.execute_input": "2024-08-28T15:42:28.983737Z",
          "iopub.status.idle": "2024-08-28T15:42:30.132021Z",
          "shell.execute_reply.started": "2024-08-28T15:42:28.983701Z",
          "shell.execute_reply": "2024-08-28T15:42:30.130946Z"
        },
        "trusted": true,
        "id": "u43_JiFI1zL1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Image(filename=f'{HOME}/runs/{train_folder}/train/results.png', width=600)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-08-28T15:42:30.133661Z",
          "iopub.execute_input": "2024-08-28T15:42:30.134001Z",
          "iopub.status.idle": "2024-08-28T15:42:30.14692Z",
          "shell.execute_reply.started": "2024-08-28T15:42:30.133965Z",
          "shell.execute_reply": "2024-08-28T15:42:30.145796Z"
        },
        "trusted": true,
        "id": "k7qBjBkY1zL1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Prediction"
      ],
      "metadata": {
        "_uuid": "a27d0804-5d2d-4295-857d-f780eb66b89e",
        "_cell_guid": "3ed4b852-f0c4-45f1-8378-b385238616ff",
        "trusted": true,
        "id": "ws0d70eo1zL1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load a model\n",
        "model = YOLO(f'{HOME}/runs/{train_folder}/train/weights/best.pt')  # load a custom model\n",
        "\n",
        "# Predict with the model\n",
        "results = model(f'{COCO_PATH}/test2017/000000000016.jpg', save=True, imgsz=320, conf=0.5)  # predict on an image\n",
        "\n",
        "# Display the prediction image\n",
        "Image(filename=f'runs/{train_folder}/predict/000000000016.jpg', height=600)"
      ],
      "metadata": {
        "_uuid": "067772a1-6d82-49d1-b523-1236778ba006",
        "_cell_guid": "50d4d5e3-50ad-48f1-ae02-d05e443951f2",
        "jupyter": {
          "outputs_hidden": false
        },
        "execution": {
          "iopub.status.busy": "2024-08-28T15:42:30.14906Z",
          "iopub.execute_input": "2024-08-28T15:42:30.149488Z",
          "iopub.status.idle": "2024-08-28T15:42:30.597498Z",
          "shell.execute_reply.started": "2024-08-28T15:42:30.149442Z",
          "shell.execute_reply": "2024-08-28T15:42:30.596516Z"
        },
        "trusted": true,
        "id": "6GiAPJUK1zL1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict with the model\n",
        "results = model(f'{COCO_PATH}/test2017/000000000001.jpg', save=True, imgsz=320, conf=0.5)  # predict on an image\n",
        "\n",
        "# Display the prediction image\n",
        "Image(filename=f'runs/{train_folder}/predict/000000000001.jpg', height=600)"
      ],
      "metadata": {
        "_uuid": "f535ed39-9675-430e-9501-daad025ae94b",
        "_cell_guid": "f731ee86-ea24-4287-820b-f8b315875c53",
        "jupyter": {
          "outputs_hidden": false
        },
        "execution": {
          "iopub.status.busy": "2024-08-28T15:42:30.598917Z",
          "iopub.execute_input": "2024-08-28T15:42:30.599273Z",
          "iopub.status.idle": "2024-08-28T15:42:30.704913Z",
          "shell.execute_reply.started": "2024-08-28T15:42:30.599237Z",
          "shell.execute_reply": "2024-08-28T15:42:30.703904Z"
        },
        "trusted": true,
        "id": "iJF7Z2q31zL1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}